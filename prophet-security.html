<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Prophet Security | Brent Benson</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    :root {
      --blueprint:#005a9c;
      --graphite:#2d2d2d;
      --paper:#f5f5f0;
    }
    *{box-sizing:border-box;margin:0;padding:0;}
    body{
      font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",sans-serif;
      background:var(--paper);
      color:var(--graphite);
      line-height:1.6;
    }
    header{
      position:sticky;
      top:0;
      z-index:10;
      background:#fff;
      border-bottom:1px solid rgba(0,0,0,0.08);
    }
    .nav{
      max-width:1024px;
      margin:0 auto;
      padding:0.75rem 1.5rem;
      display:flex;
      align-items:center;
      justify-content:space-between;
    }
    .logo{
      font-weight:700;
      letter-spacing:0.08em;
      font-size:0.9rem;
      text-transform:uppercase;
      padding:0.25rem 0.5rem;
      border:1px solid var(--graphite);
    }
    .nav ul{
      list-style:none;
      display:flex;
      gap:1rem;
      font-size:0.9rem;
    }
    .nav a{
      text-decoration:none;
      color:var(--graphite);
      padding:0.25rem 0.5rem;
      border-radius:999px;
      transition:background 0.15s ease,color 0.15s ease;
    }
    .nav a:hover{
      background:var(--blueprint);
      color:#fff;
    }

    main{
      max-width:1024px;
      margin:0 auto;
      padding:2rem 1.5rem 3rem;
    }

    .kicker{
      font-size:0.78rem;
      text-transform:uppercase;
      letter-spacing:0.18em;
      color:#777;
      margin-bottom:0.9rem;
    }
    h1{
      font-size:1.9rem;
      margin-bottom:0.5rem;
    }
    .intro{
      max-width:640px;
      font-size:0.98rem;
      margin-bottom:2rem;
    }

    .section-title{
      font-size:1.4rem;
      margin-bottom:0.4rem;
    }

    .two-column{
      display:grid;
      grid-template-columns:minmax(0,1.3fr) minmax(0,1fr);
      gap:2rem;
      align-items:flex-start;
      margin-bottom:2.5rem;
    }
    .card-list{
      display:grid;
      gap:1rem;
    }
    .card{
      background:#fff;
      border-radius:0.85rem;
      padding:1rem 1.1rem;
      border:1px solid rgba(0,0,0,0.06);
    }
    .pill{
      display:inline-flex;
      font-size:0.7rem;
      text-transform:uppercase;
      letter-spacing:0.12em;
      padding:0.15rem 0.6rem;
      border-radius:999px;
      border:1px solid rgba(0,0,0,0.16);
      margin-bottom:0.35rem;
      color:#555;
    }
    .card h2{
      font-size:1.05rem;
      margin-bottom:0.25rem;
    }
    .card h3{
      font-size:1.02rem;
      margin-bottom:0.25rem;
    }
    .meta{
      font-size:0.8rem;
      color:#777;
      margin-top:0.35rem;
    }

    table{
      width:100%;
      border-collapse:collapse;
      font-size:0.9rem;
    }
    table th, table td{
      border:1px solid rgba(0,0,0,0.1);
      padding:0.6rem 0.6rem;
      vertical-align:top;
      text-align:left;
    }
    table th{
      background:#f0f0f0;
      font-weight:600;
    }

    .title-row {
      display:flex;
      align-items:flex-start;
      justify-content:space-between;
      gap:1.5rem;
      margin-bottom:2rem;
    }
    .title-text {
      flex:1.4;
    }
    .title-logo {
      flex:0.8;
      display:flex;
      align-items:flex-start;
      justify-content:flex-end;
    }
    .rf-logo {
      max-width:220px;
      height:auto;
      opacity:0.95;
    }

    @media(max-width:768px){
      .two-column{
        grid-template-columns:1fr;
      }
      .nav{
        flex-direction:column;
        align-items:flex-start;
        gap:0.5rem;
      }
      .nav ul{
        flex-wrap:wrap;
        justify-content:flex-start;
      }
      .title-row{
        flex-direction:column;
        align-items:flex-start;
      }
      .title-logo{
        justify-content:flex-start;
      }
      .rf-logo{
        max-width:200px;
      }
    }
  </style>
</head>
<body>
<header>
  <nav class="nav">
    <div class="logo">BB</div>
    <ul>
      <li><a href="index.html">Home</a></li>
      <li><a href="work.html">Work</a></li>
      <li><a href="life.html">Life</a></li>
      <li><a href="notes.html">Notes</a></li>
    </ul>
  </nav>
</header>

<main>
  <div class="kicker">Target company</div>

  <div class="title-row">
    <div class="title-text">
      <h1>Prophet Security: Agentic SOC territory view</h1>
      <p class="intro">
        This page shows how I think about Prophet Security and an Agentic SOC motion in Minnesota and Iowa using a Gap Selling lens:
        the problems large SOCs and MDR customers face today, the business impact of those problems, and the root causes that keep
        them there, plus how I would build a focused account plan.
      </p>
    </div>
    <div class="title-logo">
      <!-- update src to your actual Prophet logo file path -->
      <img src="images/prophet-security-logo.png" alt="Prophet Security logo" class="rf-logo">
    </div>
  </div>

  <!-- Section 1: Problems / impact / causes (Agentic SOC) -->
  <section>
    <div class="kicker">Problems, impact, causes</div>
    <h2 class="section-title">How an Agentic SOC from Prophet maps to customer gaps</h2>
    <p class="intro">
      Prophet’s Agentic SOC model fits naturally into Gap Selling-style problems, impacts, and root causes across core SOC operations,
      MDR shortcomings, and the realities of large, tool-heavy security programs.
    </p>

    <!-- Core SOC problems for Prophet -->
    <h3 class="section-title" style="font-size:1.1rem; margin-top:1.5rem;">Core SOC problems Prophet addresses</h3>
    <div style="overflow-x:auto; margin-top:0.5rem;">
      <table>
        <thead>
          <tr>
            <th>Problem (customer’s world)</th>
            <th>Business impact</th>
            <th>Likely root causes</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>Alert fatigue and high manual investigation load in the SOC</strong></td>
            <td>
              Analysts spend 20–60 minutes per alert, limiting throughput to tens of alerts per analyst per day. Real deployments have seen
              average investigation time drop from about 30 minutes to about 5 minutes per alert, yielding roughly 10x SOC throughput and
              double-digit days of analyst time saved in a single quarter. Reclaiming even 20–30 percent of analyst time effectively returns
              tens of thousands of dollars per analyst per year.
            </td>
            <td>
              Highly manual triage and investigation where analysts pivot between SIEM, EDR, identity, and cloud tools to collect context,
              brittle SOAR playbooks that cover only a subset of scenarios, and a historic focus on adding tools and telemetry without
              deep automation and correlation.
            </td>
          </tr>
          <tr>
            <td><strong>High MTTR and dwell time for real threats</strong></td>
            <td>
              Longer mean time to respond increases the likelihood and impact of successful breaches. AI SOC agents can reduce MTTR by
              multiples, turning investigations that took hours into minutes. Each extra hour or day of dwell time raises potential
              incident cost across investigation, containment, recovery, and business disruption.
            </td>
            <td>
              Investigation bottlenecks with humans performing serial investigations and queuing alerts, high false-positive volume
              that consumes analyst attention, and limited use of autonomous investigation and response that can act immediately when
              an alert fires.
            </td>
          </tr>
          <tr>
            <td><strong>Large volume of false positives consuming SOC capacity</strong></td>
            <td>
              SOCs can receive thousands of alerts per day; a large share are false positives. In one example, an AI SOC processed
              thousands of alerts in a month but escalated only a handful of true critical issues, letting the agent close benign alerts
              autonomously. Reducing false positives at scale cuts wasted analyst hours and telemetry costs and lowers the risk that
              real threats are missed amid noise.
            </td>
            <td>
              Detection rules tuned defensively to avoid misses and vendor defaults generating excessive noise, limited contextual
              enrichment at triage time, and no system that can safely and transparently close benign alerts with a full audit trail,
              so teams err on the side of manual review.
            </td>
          </tr>
          <tr>
            <td><strong>SOC headcount does not scale with alert volume and tooling</strong></td>
            <td>
              Average fully loaded analyst cost is high, and increasing coverage by adding headcount can require hundreds of thousands
              to millions of dollars over a few years, plus turnover cost when analysts leave. An Agentic SOC lets teams handle far more
              alerts with the same or smaller team; customers report AI effectively “paying for itself” within a year via investigation
              time saved and avoided headcount.
            </td>
            <td>
              Security leaders have treated headcount as the primary lever for growth, many SOC tools assume humans are the core processing
              engine, and a lack of clear ROI models for AI-driven operations has delayed serious investment in automation.
            </td>
          </tr>
          <tr>
            <td><strong>High analyst burnout and attrition due to repetitive work</strong></td>
            <td>
              Industry reports show analysts spending most of their day on repetitive, manual tasks, which drives burnout and turnover.
              Replacing an experienced analyst can cost 1.5–2x their salary. With an agent handling the tedious parts of investigations,
              analysts can move to higher-value work like threat hunting and detection engineering, improving satisfaction and retention.
            </td>
            <td>
              Job design centered on “alert chasing” and low-value manual investigation, limited investment in automation that can take
              over the tedious parts of the job, and culture and tooling that do not prioritize analyst experience or sustainable workloads.
            </td>
          </tr>
          <tr>
            <td><strong>Underutilized security tool stack and bloated SIEM costs</strong></td>
            <td>
              Many organizations pay heavily for SIEM ingestion and storage yet use only a fraction of that data for investigations.
              Case studies show SIEM spend reduced dramatically by letting an AI agent pull evidence directly from native systems instead
              of centralizing everything. Overlapping tools and duplicative workflows increase license costs and complexity, lowering ROI.
            </td>
            <td>
              Tool sprawl as point solutions were added over time without a unifying investigation layer, SIEM-centric architectures that
              centralize everything by default rather than querying on demand, and a lack of metrics that tie data retention to concrete
              investigation value.
            </td>
          </tr>
          <tr>
            <td><strong>Lack of transparency and trust in AI recommendations</strong></td>
            <td>
              If analysts do not trust AI outputs, they redo investigations manually, erasing time savings and keeping MTTR high.
              Low trust reduces adoption and undermines the ROI promised on AI investments. A transparent AI SOC that shows every
              step and piece of evidence lets analysts “grade the homework” instead of redoing it.
            </td>
            <td>
              Black-box AI tools that provide conclusions without showing steps or evidence, early AI focused on simple triage scoring
              instead of full investigations, and no consistent framework for measuring AI accuracy and establishing human-in-the-loop
              feedback.
            </td>
          </tr>
          <tr>
            <td><strong>Incomplete or inconsistent SOC metrics and reporting</strong></td>
            <td>
              Without clear metrics like MTTD, MTTR, false positive rates, and investigation throughput, leaders cannot quantify risk
              or ROI, which makes it hard to justify budgets and improvements. Poor metrics lead to misallocated investments, often
              toward more tools instead of efficiency and depth of investigation.
            </td>
            <td>
              Legacy reporting focused on volume and activity (alerts processed, tickets closed) rather than outcomes and efficiency,
              fragmented tools and data that make consolidation hard, and no purpose-built AI SOC layer that exposes consistent
              end-to-end investigation telemetry.
            </td>
          </tr>
        </tbody>
      </table>
    </div>

    <!-- MDR-specific problems -->
    <h3 class="section-title" style="font-size:1.1rem; margin-top:1.75rem;">MDR-specific problems an Agentic SOC can solve</h3>
    <div style="overflow-x:auto; margin-top:0.5rem;">
      <table>
        <thead>
          <tr>
            <th>Problem (MDR customer’s world)</th>
            <th>Business impact</th>
            <th>Likely root causes</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>MDR ignores or downplays low and medium alerts where early compromise lives</strong></td>
            <td>
              Human MDR teams focus on high severity alerts to stay afloat, so subtle identity or SaaS signals early in an attack
              are often never investigated. This increases breach likelihood and dwell time, turning small incidents into large,
              costly events while the organization still pays full MDR fees.
            </td>
            <td>
              Human-only MDR models cannot economically investigate every low-severity alert across EDR, identity, SaaS, cloud,
              and email, and services are optimized for scalable, repeatable detections rather than deep, client-specific weak signals.
            </td>
          </tr>
          <tr>
            <td><strong>Loss of organizational context when incidents are outsourced to MDR</strong></td>
            <td>
              Alerts get closed as benign because MDR analysts do not know local changes, business processes, or legitimate but
              unusual behavior. Correlations across identity, cloud, and business apps are often missed, leaving gaps in detection
              and incident understanding.
            </td>
            <td>
              MDR analysts sit outside the organization and rarely have full access to internal context, and playbooks and detections
              are built for the “average customer” rather than tailored to each environment.
            </td>
          </tr>
          <tr>
            <td><strong>Limited support for custom detections and unique use cases</strong></td>
            <td>
              Mature security programs struggle to operationalize their custom detections through MDR and end up running parallel
              internal processes, which leads to duplicated effort, slower responses, and missed ROI on both MDR and internal investments.
            </td>
            <td>
              MDR offerings are designed to be standardized and scalable, prioritizing generic detection content over customer-specific
              detections, and contracts and tooling often make it hard to push bespoke rules into MDR workflows.
            </td>
          </tr>
          <tr>
            <td><strong>High recurring MDR cost without proportional reduction in internal workload</strong></td>
            <td>
              Many customers keep internal analysts “watching the watchers,” re-validating MDR alerts and doing internal investigations
              on top. They pay both MDR fees and internal headcount yet still struggle with alert fatigue.
            </td>
            <td>
              MDR was adopted as a way to “buy a SOC,” but internal complexity (cloud, SaaS, identity) continued to grow while MDR
              scope did not, and there is often no clear metric framework for how much work MDR actually removed.
            </td>
          </tr>
          <tr>
            <td><strong>Slow, ticket-driven back-and-forth during active incidents</strong></td>
            <td>
              During serious incidents, internal teams and MDR analysts often rely on slow ticket updates and scheduled calls,
              which can add hours or days to timelines and expand the blast radius of an incident.
            </td>
            <td>
              MDR processes were built around tickets, SLAs, and escalation paths, not around unified, shared investigative timelines,
              and MDR and customer teams often use different tools and data sources.
            </td>
          </tr>
          <tr>
            <td><strong>Limited transparency into how MDR reached conclusions</strong></td>
            <td>
              Security leaders struggle to audit MDR decisions or learn from incidents because they receive summaries rather than
              full step-by-step investigations, so internal teams often redo parts of the work.
            </td>
            <td>
              MDR workflows and tools are proprietary and optimized for internal efficiency rather than customer visibility, and
              reports are often abstracted for executives instead of exposing investigative detail.
            </td>
          </tr>
          <tr>
            <td><strong>Inflexible service model as environments expand</strong></td>
            <td>
              MDR coverage often lags where risk moves (identity, SaaS, OT), leaving blind spots where customers must still build
              monitoring and response on their own, creating a patchwork between MDR and internal coverage.
            </td>
            <td>
              MDRs were born in an endpoint-centric world and expanded gradually, and onboarding new data sources into MDR workflows
              is expensive and standardized rather than adaptive to each environment.
            </td>
          </tr>
          <tr>
            <td><strong>Difficulty measuring MDR’s true ROI vs an AI-augmented in-house SOC</strong></td>
            <td>
              Without granular metrics on investigation time, MTTR, false positives, and human hours saved, it is hard to prove MDR
              is more effective than investing in an AI-driven internal SOC, which makes renewal and transformation decisions hard.
            </td>
            <td>
              MDR reporting focuses on tickets handled and coverage rather than unit economics per investigation or saved analyst hour,
              and there is no internal framework to compare MDR output to what an AI SOC platform could do on the same alerts.
            </td>
          </tr>
        </tbody>
      </table>
    </div>

    <!-- Problems in large SOCs -->
    <h3 class="section-title" style="font-size:1.1rem; margin-top:1.75rem;">Problems in large SOCs Prophet can address</h3>
    <div style="overflow-x:auto; margin-top:0.5rem;">
      <table>
        <thead>
          <tr>
            <th>Problem (in a mature SOC)</th>
            <th>Business impact</th>
            <th>Likely root causes</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>Alert volume outstrips analyst capacity, even with SIEM and SOAR</strong></td>
            <td>
              Large enterprises see thousands of alerts per day from many alert-generating tools, and even strong SOCs cannot
              investigate all of them thoroughly. At 30–60 minutes per investigation, that is hundreds of analyst hours per month,
              translating into significant fully loaded cost and higher breach risk.
            </td>
            <td>
              Stack evolution focused on adding more detection tools and telemetry, SOAR automating steps but still relying on humans
              to drive investigations, and SIEM optimized for aggregation and search rather than autonomously doing analyst work.
            </td>
          </tr>
          <tr>
            <td><strong>SIEM and data storage costs are high, but much of the data is under-used</strong></td>
            <td>
              Very large organizations ingest logs from dozens of tools; SIEM licensing and storage can be very expensive while a
              significant portion of data is rarely queried. Case studies show AI SOC platforms reducing SIEM-related spend by
              shifting to on-demand evidence collection.
            </td>
            <td>
              An “ingest everything” mindset where SIEM is treated as the only analysis layer, lack of targeted, on-demand data access
              models, and no clear mapping between data sources, investigations closed, and business value.
            </td>
          </tr>
          <tr>
            <td><strong>Tool sprawl and fragmented workflows across SIEM, EDR, IAM, cloud, and SaaS</strong></td>
            <td>
              Security teams often manage dozens of alert-generating tools with separate consoles. Investigations require pivoting
              across multiple systems, extending time per case and increasing the risk of missing cross-domain attack paths.
            </td>
            <td>
              Point solutions added over years to solve specific problems without a unifying investigation and orchestration layer,
              SOAR scripts built per tool rather than end-to-end, and SIEM correlating logs but still leaving humans to stitch together
              a coherent narrative.
            </td>
          </tr>
          <tr>
            <td><strong>MTTR remains high despite “good tools” and a staffed SOC</strong></td>
            <td>
              Even with SIEM and EDR, organizations struggle with MTTR because investigations queue behind other work. An Agentic SOC
              can cut investigation time sharply and increase throughput, directly reducing dwell time and incident scope.
            </td>
            <td>
              Investigations are still driven by humans pulling data and writing timelines, metrics focus on alerts handled instead of
              time from detection to remediation, and limited automation exists for medium severity issues.
            </td>
          </tr>
          <tr>
            <td><strong>Skilled analysts spend too much time on repetitive triage</strong></td>
            <td>
              High-cost senior analysts spend large portions of each day validating obvious false positives, copy-pasting evidence, and
              documenting investigations. AI SOC customers report reclaiming enough time that AI delivers the efficiency of a much larger team.
            </td>
            <td>
              No AI analyst taking the first pass at every alert with transparent, auditable output, SOAR focused on actions rather than
              reasoning, and processes that remain analyst-centric even when automation could safely handle much of the work.
            </td>
          </tr>
          <tr>
            <td><strong>Alert fatigue and intentional suppression of detections to keep workload manageable</strong></td>
            <td>
              To cope with unsustainable alert volume, teams suppress detections they would otherwise enable, especially for cloud and
              identity, increasing blind spots where attackers can move.
            </td>
            <td>
              Investigation capacity limited by humans, no mechanism to offload extra detections to an AI investigator that can filter
              and escalate only what matters, and historical attempts to do this with brittle rules and scripts.
            </td>
          </tr>
          <tr>
            <td><strong>Difficulty turning SOC operations into a clear, defensible ROI story</strong></td>
            <td>
              CISOs struggle to show how SOC investments reduce risk or cost because most metrics are operational rather than financial.
              An Agentic SOC can surface concrete metrics like investigation time reductions, throughput gains, and SIEM cost savings.
            </td>
            <td>
              Reporting focused on activity instead of outcomes, no consistent unit economics model for SOC work, and limited visibility
              into how much human time and risk is actually reduced by existing tooling.
            </td>
          </tr>
        </tbody>
      </table>
    </div>
  </section>

  <!-- Section 2: Territory strategy -->
  <section>
    <div class="kicker">Territory</div>
    <h2 class="section-title">How I’d approach MN, WI, ND, and SD for Prophet</h2>
    <div class="two-column">
      <div>
        <p>
          For Prophet’s Agentic SOC, I would segment Minnesota, Wisconsin, North Dakota, and South Dakota into two parallel motions:
          a focused list of large enterprises with established SOC teams, and a broader set of smaller organizations that look more
          like MDR buyers with small or no internal security teams.
        </p>
        <p style="margin-top:0.75rem;">
          To build sustainable pipeline, I would work both tracks at the same time: 10–20 large Fortune‑500/1000‑scale or SOC‑mature
          organizations, and roughly 40–60 smaller organizations across verticals where an Agentic SOC can compete directly with or
          replace MDR.
        </p>
      </div>
      <div class="card-list">
        <article class="card">
          <div class="pill">Segmentation</div>
          <h3>Large SOCs and MDR‑style buyers</h3>
          <p>
            Identify 10–20 large enterprises in MN, WI, ND, and SD with established SOCs, SIEM and EDR investments, and clear alert
            fatigue, plus 40–60 smaller organizations with limited security staff or MDR contracts that want better coverage and
            transparency.
          </p>
        </article>
        <article class="card">
          <div class="pill">Signals</div>
          <h3>Two sets of buying signals</h3>
          <p>
            For large SOCs, look for SOC and detection engineering roles, SIEM/EDR/ SOAR stacks, and talk of MTTR and tool sprawl.
            For MDR‑style buyers, look for “security analyst 1 of 1,” MDR/RMM mentions, compliance‑driven security, and leaders worried
            about coverage without adding headcount.
          </p>
        </article>
        <article class="card">
          <div class="pill">Motion</div>
          <h3>Different motions, same outcome</h3>
          <p>
            With big SOCs, lead with investigation time, MTTR, SIEM cost, and analyst burnout. With smaller orgs, lead with MDR
            frustrations, 24x7 coverage, and faster investigations, then show how an Agentic SOC changes both the cost curve and
            response quality.
          </p>
        </article>
      </div>
    </div>
  </section>

  <!-- Section 3: Account research framework -->
  <section>
    <div class="kicker">Account research</div>
    <h2 class="section-title">How I’d build an Agentic SOC account plan</h2>
    <p class="intro">
      In this territory I’d maintain two structured lists: 10–20 large SOC‑mature enterprises and 40–60 smaller organizations
      that resemble MDR buyers. Each account gets a simple profile that ties their environment and signals back to a specific
      Agentic SOC problem set.
    </p>

    <div style="overflow-x:auto;">
      <table>
        <thead>
          <tr>
            <th>Account (example)</th>
            <th>Type / HQ</th>
            <th>Signals I’d look for</th>
            <th>Agentic SOC problem to test</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Large upper‑Midwest healthcare system</td>
            <td>Large enterprise · Healthcare · MN or WI</td>
            <td>
              Dedicated SOC team, SIEM and EDR stack, job posts for SOC, detection engineers, and IR; public discussion of compliance,
              cyber risk, or recent sector incidents.
            </td>
            <td>
              High alert volume, long investigation times, and SIEM cost in a regulated environment where Prophet can cut MTTR,
              reduce manual hours, and shrink storage and MDR dependence.
            </td>
          </tr>
          <tr>
            <td>Regional financial services HQ</td>
            <td>Large enterprise · Banking / insurance · MN or WI</td>
            <td>
              SOC and fraud team roles, references to SOC modernization or MDR partnerships, heavy use of Microsoft or Splunk,
              and board‑level focus on cyber and fraud risk.
            </td>
            <td>
              Need to handle far more alerts with the same team, reduce false positives, and get transparent AI investigations that
              stand up to auditors and regulators.
            </td>
          </tr>
          <tr>
            <td>Manufacturing leader with plants across the upper Midwest</td>
            <td>Large enterprise · Manufacturing · MN / ND / SD</td>
            <td>
              IT/OT environments, job posts linking OT and IT security, SIEM/EDR in plants and corporate, and any history of ransomware
              or production outages due to cyber issues.
            </td>
            <td>
              Mixed IT/OT alerts overwhelming a small central SOC, where an Agentic SOC can scale investigations without adding many
              analysts and reduce dwell time on true incidents.
            </td>
          </tr>
          <tr>
            <td>Regional healthcare provider with small IT team</td>
            <td>Smaller org · Healthcare · SD or ND</td>
            <td>
              One‑to‑few security staff, security responsibilities rolled into broader IT roles, references to MDR or outsourced SOC,
              and compliance pressure (HIPAA, etc.).
            </td>
            <td>
              Over‑reliance on MDR or basic tools with limited transparency; Prophet can act as an AI SOC analyst that gives 24x7
              coverage, faster investigations, and clear timelines without hiring a full team.
            </td>
          </tr>
          <tr>
            <td>Multi‑site retailer or franchise group</td>
            <td>Smaller org · Retail · MN / WI / ND / SD</td>
            <td>
              Central IT with minimal security headcount, cloud and SaaS footprint (POS, e‑commerce, Office 365), and job posts
              focused on “security‑minded IT generalists.”
            </td>
            <td>
              Alert noise from endpoint, email, and identity tools with no real SOC; Prophet can function as an Agentic SOC layer that
              triages and investigates alerts so a small team is not overwhelmed.
            </td>
          </tr>
          <tr>
            <td>Regional professional services or SaaS provider</td>
            <td>Smaller org · SaaS / services · MN or WI</td>
            <td>
              ISO/SOC 2 or similar compliance focus, MDR or MSSP relationships, and CEO/CISO commentary about needing “enterprise‑grade”
              security on a mid‑market budget.
            </td>
            <td>
              Desire to move beyond basic MDR to something that can investigate every alert and show clear ROI on security spend,
              without building a full internal SOC.
            </td>
          </tr>
        </tbody>
      </table>
    </div>

    <p style="margin-top:1rem; font-size:0.9rem;">
      Operationally, I’d track these profiles in a simple two‑tier view: 10–20 large SOC‑mature logos and 40–60 MDR‑style buyers,
      each mapped to MEDDPICC fields, current tooling, and the Prophet value story I want to test first.
    </p>
  </section>
</main>
</body>
</html>
